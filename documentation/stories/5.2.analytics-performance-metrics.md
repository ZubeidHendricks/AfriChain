# Story 5.2: Analytics & Performance Metrics

## Status
Done

## Story
**As an** admin,
**I want** system analytics,
**so that** I can measure detection effectiveness.

## Acceptance Criteria
1. Detection rate dashboard (targeting 85%+)
2. False positive tracking (<5% target)
3. Response time monitoring (<3 seconds per product)
4. Bias detection and fairness metrics

## Tasks / Subtasks
- [x] Task 1: Implement comprehensive detection analytics system (AC: 1)
  - [x] Create `AnalyticsService` in `src/counterfeit_detection/services/analytics_service.py`
  - [x] Build detection rate calculation engine with 85%+ target tracking
  - [x] Implement time-series analytics with daily/weekly/monthly aggregations
  - [x] Create analytics dashboard API endpoints with caching and optimization
- [x] Task 2: Implement false positive tracking and management (AC: 2)
  - [x] Create false positive feedback loop from admin overrides and appeals
  - [x] Calculate false positive rates by category, supplier, and time period
  - [x] Implement automated alerts when false positive rate exceeds 5% threshold
  - [x] Build false positive trend analysis with root cause identification
- [x] Task 3: Create comprehensive performance monitoring system (AC: 3)
  - [x] Implement performance timing collection across all system components
  - [x] Create response time dashboards tracking <3s per product target
  - [x] Add agent performance monitoring (uptime, processing speed, error rates)
  - [x] Implement performance optimization recommendations and alerting
- [x] Task 4: Build bias detection and fairness monitoring (AC: 4)
  - [x] Implement fairness metrics across product categories, price ranges, suppliers
  - [x] Create statistical bias detection algorithms (demographic parity, equalized odds)
  - [x] Add bias monitoring dashboard with <1% bias trigger rate target
  - [x] Implement automated bias alert system with corrective action recommendations

## Dev Notes
This story implements the comprehensive analytics and performance monitoring system that tracks all key success metrics and provides actionable insights.

**Analytics Architecture** [Source: docs/architecture/project-structure.md]:
```python
# Analytics service and components
src/counterfeit_detection/analytics/
├── services/
│   ├── analytics_service.py      # Core analytics calculations
│   ├── metrics_collector.py      # Real-time metrics collection
│   ├── bias_detector.py          # Fairness and bias monitoring
│   └── performance_monitor.py    # System performance tracking
├── models/
│   ├── metrics.py               # Analytics data models
│   └── aggregations.py          # Time-series aggregation models
├── calculators/
│   ├── detection_rate.py        # Detection rate calculations
│   ├── false_positive.py        # FP rate tracking
│   └── fairness_metrics.py      # Bias detection algorithms
└── exporters/
    ├── report_generator.py      # Automated reporting
    └── compliance_exporter.py   # Regulatory compliance reports
```

**Database Schema for Analytics** [Source: docs/architecture/database-schema.md]:
```sql
-- Metrics aggregation tables
CREATE TABLE daily_analytics (
    id VARCHAR(36) PRIMARY KEY,
    date DATE NOT NULL UNIQUE,
    total_products_analyzed INT DEFAULT 0,
    products_flagged INT DEFAULT 0,
    detection_rate DECIMAL(5,2) DEFAULT 0.00,  -- Percentage
    false_positive_count INT DEFAULT 0,
    false_positive_rate DECIMAL(5,2) DEFAULT 0.00,
    avg_processing_time_ms INT DEFAULT 0,
    agent_uptime_percent DECIMAL(5,2) DEFAULT 100.00,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE performance_metrics (
    id VARCHAR(36) PRIMARY KEY,
    component_name VARCHAR(100) NOT NULL,  -- 'llm_agent', 'rule_engine', 'vector_search'
    metric_type VARCHAR(50) NOT NULL,      -- 'response_time', 'throughput', 'error_rate'
    metric_value DECIMAL(10,4) NOT NULL,
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    INDEX idx_component_timestamp (component_name, timestamp),
    INDEX idx_metric_type_timestamp (metric_type, timestamp)
);

CREATE TABLE bias_monitoring (
    id VARCHAR(36) PRIMARY KEY,
    analysis_date DATE NOT NULL,
    category VARCHAR(100),
    supplier_id VARCHAR(36),
    price_range VARCHAR(20),  -- 'low', 'medium', 'high', 'luxury'
    total_products INT NOT NULL,
    flagged_products INT NOT NULL,
    flagging_rate DECIMAL(5,2) NOT NULL,
    expected_rate DECIMAL(5,2) NOT NULL,
    bias_score DECIMAL(5,4) NOT NULL,  -- Statistical significance
    bias_detected BOOLEAN DEFAULT FALSE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    INDEX idx_analysis_date (analysis_date),
    INDEX idx_bias_detected (bias_detected, analysis_date)
);

CREATE TABLE false_positive_tracking (
    id VARCHAR(36) PRIMARY KEY,
    product_id VARCHAR(36) NOT NULL,
    original_score INT NOT NULL,
    human_decision ENUM('authentic', 'counterfeit', 'uncertain'),
    correction_reason TEXT,
    corrected_by VARCHAR(36) NOT NULL,  -- user_id
    corrected_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    model_version VARCHAR(50),
    
    INDEX idx_corrected_at (corrected_at),
    INDEX idx_human_decision (human_decision)
);
```

**Success Metrics Implementation** [Source: docs/5-success-metrics.md]:
```python
# Key performance indicators with targets
SUCCESS_METRICS = {
    "detection_kpis": {
        "authenticity_detection_rate": {
            "target": 85.0,  # Percentage
            "calculation": "(true_positives + true_negatives) / total_analyzed",
            "alert_threshold": 80.0
        },
        "false_positive_rate": {
            "target": 5.0,   # Maximum percentage
            "calculation": "false_positives / (false_positives + true_negatives)",
            "alert_threshold": 7.0
        },
        "time_to_detection": {
            "target": 3.0,   # Seconds
            "calculation": "avg(analysis_duration_ms) / 1000",
            "alert_threshold": 5.0
        }
    },
    "business_value": {
        "counterfeit_reduction": {
            "target": 50.0,  # Percentage reduction
            "calculation": "(baseline_counterfeits - current_counterfeits) / baseline_counterfeits * 100"
        },
        "brand_trust_score": {
            "target": 8.5,   # Out of 10
            "calculation": "weighted_average(brand_satisfaction_scores)"
        }
    },
    "technical_excellence": {
        "agent_uptime": {
            "target": 99.0,  # Percentage
            "calculation": "(total_time - downtime) / total_time * 100",
            "alert_threshold": 95.0
        },
        "vector_search_speed": {
            "target": 300,   # Milliseconds
            "calculation": "avg(vector_search_duration_ms)",
            "alert_threshold": 500
        }
    },
    "ai_impact": {
        "llm_human_agreement": {
            "target": 90.0,  # Percentage
            "calculation": "agreements / total_comparisons * 100"
        },
        "bias_trigger_rate": {
            "target": 1.0,   # Maximum percentage
            "calculation": "bias_detections / total_categories * 100",
            "alert_threshold": 2.0
        }
    }
}
```

**Real-time Analytics Pipeline**:
```python
# Streaming analytics implementation
class MetricsCollector:
    def __init__(self):
        self.redis_client = Redis()
        self.db_session = AsyncSession()
    
    async def record_analysis_event(self, event: AnalysisEvent):
        """Record real-time analysis metrics"""
        # Update real-time counters in Redis
        await self.redis_client.hincrby(
            f"metrics:daily:{event.date}",
            "total_analyzed", 1
        )
        
        if event.authenticity_score < 70:
            await self.redis_client.hincrby(
                f"metrics:daily:{event.date}",
                "flagged_products", 1
            )
        
        # Record performance timing
        await self.record_performance_metric(
            component="authenticity_analyzer",
            metric_type="response_time",
            value=event.processing_time_ms
        )
    
    async def calculate_detection_rate(self, date_range: DateRange) -> float:
        """Calculate detection rate for given period"""
        query = """
        SELECT 
            COUNT(*) as total,
            SUM(CASE WHEN human_verified IS NOT NULL 
                     AND human_verified = (authenticity_score < 70) 
                     THEN 1 ELSE 0 END) as correct
        FROM authenticity_analyses 
        WHERE created_at BETWEEN %s AND %s
        """
        
        result = await self.db_session.execute(query, [date_range.start, date_range.end])
        row = result.fetchone()
        
        return (row.correct / row.total * 100) if row.total > 0 else 0.0
```

**Bias Detection Implementation**:
```python
# Fairness and bias monitoring
class BiasDetector:
    def __init__(self):
        self.fairness_threshold = 0.1  # 10% disparity threshold
    
    async def detect_demographic_bias(self, analysis_period: DateRange):
        """Detect bias across different product categories and price ranges"""
        categories = await self.get_product_categories()
        bias_results = []
        
        for category in categories:
            # Calculate flagging rates by price range within category
            rates = await self.calculate_flagging_rates_by_price(
                category, analysis_period
            )
            
            # Statistical significance test
            bias_score = self.calculate_bias_score(rates)
            
            if bias_score > self.fairness_threshold:
                bias_results.append({
                    "category": category,
                    "bias_type": "price_discrimination",
                    "bias_score": bias_score,
                    "affected_groups": self.identify_affected_groups(rates),
                    "severity": "high" if bias_score > 0.2 else "medium"
                })
        
        return bias_results
    
    def calculate_bias_score(self, rates: Dict[str, float]) -> float:
        """Calculate statistical bias score using demographic parity"""
        # Implement demographic parity calculation
        # Returns 0.0 (no bias) to 1.0 (maximum bias)
        values = list(rates.values())
        if len(values) < 2:
            return 0.0
        
        # Use coefficient of variation as bias measure
        mean = sum(values) / len(values)
        variance = sum((x - mean) ** 2 for x in values) / len(values)
        std_dev = variance ** 0.5
        
        return std_dev / mean if mean > 0 else 0.0
```

**Performance Monitoring Dashboard**:
```python
# System performance tracking
class PerformanceMonitor:
    async def get_system_health(self) -> SystemHealth:
        """Get comprehensive system health metrics"""
        return SystemHealth(
            agents=await self.get_agent_status(),
            database=await self.get_database_metrics(),
            apis=await self.get_api_performance(),
            resources=await self.get_resource_utilization()
        )
    
    async def get_agent_status(self) -> List[AgentStatus]:
        """Monitor individual agent performance"""
        agents = ['authenticity_analyzer', 'rule_engine', 'notification_agent']
        status_list = []
        
        for agent in agents:
            # Get last 5 minutes of metrics
            recent_metrics = await self.get_recent_metrics(
                agent, minutes=5
            )
            
            status_list.append(AgentStatus(
                agent_id=agent,
                uptime_percent=recent_metrics.uptime,
                avg_response_time=recent_metrics.avg_response_time,
                error_rate=recent_metrics.error_rate,
                throughput=recent_metrics.throughput,
                status="healthy" if recent_metrics.uptime > 95 else "degraded"
            ))
        
        return status_list
```

**Analytics API Endpoints** [Source: docs/architecture/api-specifications.md]:
```http
# Analytics and reporting endpoints
GET /api/v1/analytics/detection-rate?period=7d&category=luxury_goods
GET /api/v1/analytics/false-positives?period=30d&supplier_id=uuid
GET /api/v1/analytics/performance?component=all&period=1h
GET /api/v1/analytics/bias-report?period=30d&dimensions=category,price_range

# Real-time metrics
GET /api/v1/analytics/live/system-status
GET /api/v1/analytics/live/current-metrics

# Compliance reporting
GET /api/v1/analytics/compliance/monthly-report?month=2025-01
POST /api/v1/analytics/compliance/generate-report
```

**Automated Alerting System**:
```python
# Alert thresholds and notifications
ALERT_RULES = {
    "detection_rate_low": {
        "condition": "detection_rate < 80",
        "severity": "high",
        "notification_channels": ["slack", "email"],
        "escalation_time": "15m"
    },
    "false_positive_high": {
        "condition": "false_positive_rate > 7",
        "severity": "medium",
        "notification_channels": ["slack"],
        "escalation_time": "30m"
    },
    "bias_detected": {
        "condition": "bias_score > 0.1",
        "severity": "critical",
        "notification_channels": ["slack", "email", "dashboard"],
        "escalation_time": "5m"
    },
    "agent_downtime": {
        "condition": "agent_uptime < 95",
        "severity": "high",
        "notification_channels": ["slack", "pagerduty"],
        "escalation_time": "2m"
    }
}
```

**Integration Points**:
- **Data Sources**: All system components feed metrics to analytics service
- **Dashboard**: Real-time analytics displayed in admin dashboard (Story 5.1)
- **Compliance**: Regulatory reporting integration
- **Machine Learning**: False positive feedback improves model performance
- **Business Intelligence**: Executive dashboards and KPI tracking

### Testing
- Unit tests for metrics calculations
- Integration tests for data collection
- Performance tests for analytics queries
- Accuracy tests for bias detection algorithms
- Dashboard visualization tests

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-01-20 | 1.0 | Initial story creation | Sarah (PO) |

## Dev Agent Record
*This section was populated by the development agent during implementation*

### Agent Model Used
Claude 3.5 Sonnet (BMad Development Agent - James)

### Debug Log References
- Comprehensive AnalyticsService implementation with detection rate calculation engine targeting 85%+ detection rate
- False positive tracking system with <5% target monitoring and automated alerting when threshold exceeded
- Performance monitoring system tracking <3 seconds per product target with real-time metrics collection
- Bias detection algorithms implementing demographic parity, equalized odds, and equality of opportunity metrics
- Analytics repository providing SQL-based data access layer with time-series aggregations and category breakdowns
- Metrics collector service with Redis-based real-time metrics storage and background aggregation tasks
- Bias detector with statistical significance testing and automated bias alert system for <1% bias threshold
- Performance monitor with system resource tracking, agent health monitoring, and optimization recommendations
- Analytics API endpoints providing comprehensive REST interface for admin dashboard integration
- Real-time analytics pipeline with WebSocket support and background task processing

### Completion Notes List
- Implemented comprehensive AnalyticsService in `src/counterfeit_detection/services/analytics_service.py` with detection rate calculations, false positive tracking, performance metrics, and bias detection
- Created AnalyticsRepository in `src/counterfeit_detection/db/repositories/analytics_repository.py` providing SQL-based data access for metrics calculations and time-series analytics
- Built MetricsCollector service in `src/counterfeit_detection/services/metrics_collector.py` with Redis-based real-time metrics storage, background aggregation, and analysis event recording
- Developed BiasDetector service in `src/counterfeit_detection/services/bias_detector.py` implementing statistical fairness algorithms and automated bias alerting system
- Created PerformanceMonitor service in `src/counterfeit_detection/services/performance_monitor.py` with comprehensive system health monitoring and optimization recommendations
- Implemented Analytics API endpoints in `src/counterfeit_detection/api/analytics.py` providing REST interface for detection analytics, performance metrics, bias analysis, and real-time system status
- Detection rate calculation engine targeting 85%+ with comprehensive time-series analytics and category breakdown analysis
- False positive tracking system with <5% target monitoring, trend analysis, root cause identification, and automated alerting
- Performance monitoring system tracking <3 seconds per product target with agent health monitoring and resource utilization tracking
- Bias detection algorithms implementing demographic parity, equalized odds, and equality of opportunity with <1% bias threshold monitoring
- Real-time metrics collection with Redis-based storage, background aggregation tasks, and WebSocket support for live dashboard updates
- Comprehensive alert system for false positive rate exceeding 5% threshold and bias detection exceeding 1% threshold
- Performance optimization recommendations based on system health analysis and resource utilization patterns

### File List
- src/counterfeit_detection/services/analytics_service.py - Core analytics service with detection rate calculations, false positive tracking, performance metrics, and bias detection
- src/counterfeit_detection/db/repositories/analytics_repository.py - Analytics data access layer with SQL queries for metrics calculations and time-series data
- src/counterfeit_detection/services/metrics_collector.py - Real-time metrics collection service with Redis storage and background aggregation
- src/counterfeit_detection/services/bias_detector.py - Fairness monitoring service with statistical bias detection algorithms and alerting
- src/counterfeit_detection/services/performance_monitor.py - System performance monitoring with health assessment and optimization recommendations
- src/counterfeit_detection/api/analytics.py - REST API endpoints for analytics dashboard integration with comprehensive metric access

## QA Results
*Results from QA Agent review will be populated here*